{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "70c68b7c5e719eabc55196967f4d07c9",
     "grade": false,
     "grade_id": "cell-markdown-task",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Exercise 1 - Naive Bayes Classification\n",
    "(10 points)\n",
    "\n",
    "Implement a Naive Bayes classifier by finalizing the two given classes. The `BayesianLearner` class acts like a builder for the `BayesianClassifier` instances. That means that the learner gets the set of classes during its creation and the `learnExample` method of the learner is called once for each document of the training set. Internally, the learner should gather all statistics that are necessary for the classifier when processing the training examples.\n",
    "After the learner saw all training documents, the `createClassifier` method is called which creates an instance of the `BayesianClassifier` class and initializes it with the statistics gathered before. \n",
    "The classification itself is carried out by the `classify` method which takes an unknown document and assigns it one of the classes learned before.\n",
    "\n",
    "#### Hints\n",
    "\n",
    "- Please do not forget to preprocess your documents. What exactly the preprocessing does is up to you.\n",
    "- The evaluation will measure the accuracy of your classifier.\n",
    "- The evaluation in the hidden tests has three stages. \n",
    "  1. Your solution will get 4 points as soon as it is better than the baselines. The baselines are:\n",
    "     - For each class, a classifier that always returns this class.\n",
    "     - A random guesser that returns a random class.\n",
    "  2. If your solution has an accuracy >= 0.7, you will get 3 more points.\n",
    "  3. If your solution has an accuracy >= 0.8, you will get 3 more points.\n",
    "- You can download the [single-class-train.tsv](https://hobbitdata.informatik.uni-leipzig.de/teaching/SNLP/classification/single-class-train.tsv) file. It comprises one document per line. The first word is the class, followed by a tab character (`\\t`). The remaining content of the line is the text of the document.\n",
    "\n",
    "#### Notes\n",
    "\n",
    "- Do not add additional external libraries.\n",
    "- Interface\n",
    "  - You can use _[TAB]_ for autocompletion and _[SHIFT]_+_[TAB]_ for code inspection.\n",
    "  - Use _Menu_ -> _View_ -> _Toggle Line Numbers_ for debugging.\n",
    "  - Check _Menu_ -> _Help_ -> _Keyboard Shortcuts_.\n",
    "- Finish\n",
    "  - Save your solution by clicking on the _disk icon_.\n",
    "  - Finally, choose _Menu_ -> _File_ -> _Close and Halt_.\n",
    "  - Do not forget to _Submit_ your solution in the _Assignments_ view."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "a390e585964cf26b40c74f81cf74bc3e",
     "grade": false,
     "grade_id": "cell-code",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compiled\n"
     ]
    }
   ],
   "source": [
    "\n",
    "/**\n",
    " * Classifier implementing naive Bayes classification.\n",
    " */\n",
    "public class BayesianClassifier {\n",
    "    // YOUR CODE HERE\n",
    "    Set<String> uniqueWords = null;\n",
    "\tHashMap<String, Integer> updatedClassCount = null;\n",
    "\tHashMap<String, BigDecimal> updatedClassProb = null;\n",
    "\tHashMap<String, HashMap<String, Integer>> UpdatedClassWordCount = null;\n",
    "\tint globalTotalCount = 0;\n",
    "\n",
    "\tHashMap<String, Double> classProbabilites = new HashMap<>();\n",
    "\n",
    "\tpublic final static String URL_REGEX = \"((www\\\\.[\\\\s]+)|(https?://[^\\\\s]+))\";\n",
    "\tpublic final static String CONSECUTIVE_CHARS = \"([a-z])\\\\1{1,}\";\n",
    "\tpublic final static String STARTS_WITH_NUMBER = \"[1-9]\\\\s*(\\\\w+)\";\n",
    "    \n",
    "    \n",
    "    BayesianClassifier(HashMap<String, BigDecimal> classProb, HashMap<String, HashMap<String, Integer>> classWordCount,\n",
    "\t\t\tHashMap<String, Integer> classCount, int totalCount, Set<String> uniqueWords) {\n",
    "\t\tthis.updatedClassCount = classCount;\n",
    "\t\tthis.updatedClassProb = classProb;\n",
    "\t\tthis.UpdatedClassWordCount = classWordCount;\n",
    "\t\tthis.globalTotalCount = totalCount;\n",
    "\t\tthis.uniqueWords = uniqueWords;\n",
    "\n",
    "\t}\n",
    "\n",
    "\tpublic String preprocess(String text) {\n",
    "\n",
    "\t\ttext = text.replaceAll(STARTS_WITH_NUMBER, \"\");\n",
    "\n",
    "\t\t// text = text.replaceAll(\"@([^\\\\s]+)\", \"\");\n",
    "\t\ttext = text.replaceAll(\"[^\\\\s\\\\w']*\", \"\");\n",
    "\t\ttext = text.replaceAll(\"(\\\\bthe\\\\b)*\", \"\");\n",
    "\t\ttext = text.replaceAll(\"(\\\\band\\\\b)*\", \"\");\n",
    "\t\ttext = text.replaceAll(\"(\\\\ba\\\\b)*\", \"\");\n",
    "\t\ttext = text.replaceAll(\"(\\\\bis\\\\b)*\", \"\");\n",
    "\t\ttext = text.replaceAll(\"(\\\\bits\\\\b)*\", \"\");\n",
    "\t\ttext = text.replaceAll(\"(\\\\bfrom\\\\b)*\", \"\");\n",
    "\t\ttext = text.replaceAll(\"(\\\\bit\\\\b)*\", \"\");\n",
    "\t\ttext = text.replaceAll(\"(\\\\bfor\\\\b)*\", \"\");\n",
    "\t\ttext = text.replaceAll(\"(\\\\bin\\\\b)*\", \"\");\n",
    "\t\ttext = text.replaceAll(\"(\\\\bto\\\\b)*\", \"\");\n",
    "\t\ttext = text.replaceAll(\"(\\\\bof\\\\b)*\", \"\");\n",
    "\t\ttext = text.replaceAll(\"(\\\\bhas\\\\b)*\", \"\");\n",
    "\t\ttext = text.replaceAll(\"(\\\\bhad\\\\b)*\", \"\");\n",
    "\t\ttext = text.replaceAll(\"(\\\\bhave\\\\b)*\", \"\");\n",
    "\t\ttext = text.replaceAll(\"(\\\\bwas\\\\b)*\", \"\");\n",
    "\t\ttext = text.replaceAll(\"(\\\\bare\\\\b)*\", \"\");\n",
    "\t\ttext = text.replaceAll(\"(\\\\bat\\\\b)*\", \"\");\n",
    "\t\ttext = text.replaceAll(\"([0-9]+)*\", \"\");\n",
    "\n",
    "\t\treturn text;\n",
    "\t}\n",
    "\n",
    "\n",
    "    /**\n",
    "     * Classifies the given document and returns the class name.\n",
    "     */\n",
    "    public String classify(String text) {\n",
    "        String clazz = null;\n",
    "        // YOUR CODE HERE\n",
    "        \n",
    "        text = preprocess(text);\n",
    "\t\tString[] words = text.toLowerCase().split(\"[^a-z0-9']+\");\n",
    "\t\tHashMap<String, Integer> map = new HashMap<String, Integer>();\n",
    "\n",
    "\t\tint uniqueWordsSize = this.uniqueWords.size();\n",
    "\n",
    "\t\tfor (String word : words) {\n",
    "\n",
    "\t\t\tthis.uniqueWords.add(word);\n",
    "\n",
    "\t\t\tif (map.containsKey(word)) {\n",
    "\t\t\t\tint value = map.get(word);\n",
    "\t\t\t\tvalue++;\n",
    "\t\t\t\tmap.put(word, value);\n",
    "\t\t\t} else {\n",
    "\t\t\t\tmap.put(word, 1);\n",
    "\t\t\t}\n",
    "\n",
    "\t\t}\n",
    "\n",
    "\t\tBigDecimal minimum = BigDecimal.ZERO;\n",
    "\n",
    "\t\tfor (String key : this.updatedClassCount.keySet()) {\n",
    "\t\t\tBigDecimal finalProbability = BigDecimal.ONE;\n",
    "\n",
    "\t\t\tBigDecimal classProb = BigDecimal.ZERO;\n",
    "\n",
    "\t\t\tif (updatedClassProb.containsKey(key)) {\n",
    "\t\t\t\t// System.out.println(\"Class \"+key+ \" has probability\n",
    "\t\t\t\t// \"+updatedClassProb.get(key));\n",
    "\t\t\t\tclassProb = updatedClassProb.get(key);\n",
    "\t\t\t}\n",
    "\n",
    "\t\t\tHashMap<String, Integer> temp = UpdatedClassWordCount.get(key);\n",
    "\t\t\t// System.out.println(\"Temp \"+temp);\n",
    "\t\t\tint totalWordsInHapMapForThatClass = 0;\n",
    "\n",
    "\t\t\tfor (int value : temp.values()) {\n",
    "\t\t\t\ttotalWordsInHapMapForThatClass += value;\n",
    "\t\t\t}\n",
    "\n",
    "\t\t\tfor (String k : map.keySet()) {\n",
    "\t\t\t\tBigDecimal wordFrequency = BigDecimal.ZERO;\n",
    "\n",
    "\t\t\t\tif (temp.containsKey(k)) {\n",
    "\t\t\t\t\twordFrequency = new BigDecimal(temp.get(k));\n",
    "\t\t\t\t\t// System.out.println(\" word frequ for word \"+k+\" is\n",
    "\t\t\t\t\t// \"+wordFreq);\n",
    "\t\t\t\t\tBigDecimal denominator = new BigDecimal(totalWordsInHapMapForThatClass)\n",
    "\t\t\t\t\t\t\t.add(new BigDecimal(uniqueWordsSize));\n",
    "\t\t\t\t\tBigDecimal probByClass = (wordFrequency.add(BigDecimal.ONE)).divide(denominator,\n",
    "\t\t\t\t\t\t\tMathContext.DECIMAL128);\n",
    "\n",
    "\t\t\t\t\tBigDecimal power = probByClass.pow(map.get(k),MathContext.DECIMAL128);\n",
    "\t\t\t\t\tfinalProbability = finalProbability.multiply(power,MathContext.DECIMAL128);\n",
    "\n",
    "\t\t\t\t} else {\n",
    "\n",
    "\t\t\t\t\tBigDecimal denominator = (new BigDecimal(totalWordsInHapMapForThatClass))\n",
    "\t\t\t\t\t\t\t.add(new BigDecimal(uniqueWordsSize));\n",
    "\t\t\t\t\tBigDecimal probByClass = (BigDecimal.ONE).divide(denominator, MathContext.DECIMAL128);\n",
    "\n",
    "\t\t\t\t\tBigDecimal power = probByClass.pow(map.get(k),MathContext.DECIMAL128);\n",
    "\t\t\t\t\tfinalProbability = finalProbability.multiply(power,MathContext.DECIMAL128);\n",
    "\n",
    "\t\t\t\t}\n",
    "\n",
    "\t\t\t}\n",
    "\n",
    "\t\t\tfinalProbability = finalProbability.multiply(classProb,MathContext.DECIMAL128);\n",
    "\n",
    "\t\t\tif (finalProbability.compareTo(minimum) == 1) {\n",
    "\t\t\t\tclazz = key;\n",
    "\t\t\t\tminimum = finalProbability;\n",
    "\t\t\t}\n",
    "\n",
    "\t\t}\n",
    "\n",
    "\t\t// update ClassCounr Map\n",
    "\t\tglobalTotalCount++;\n",
    "\n",
    "\t\tif (updatedClassCount.containsKey(clazz)) {\n",
    "\t\t\tint value = updatedClassCount.get(clazz);\n",
    "\t\t\tvalue++;\n",
    "\t\t\tupdatedClassCount.put(clazz, value);\n",
    "\n",
    "\t\t\tfor (String key : updatedClassCount.keySet()) {\n",
    "\t\t\t\tBigDecimal value1 = (new BigDecimal(updatedClassCount.get(key)))\n",
    "\t\t\t\t\t\t.divide(new BigDecimal(globalTotalCount), MathContext.DECIMAL128);\n",
    "\t\t\t\tupdatedClassProb.put(key, value1);\n",
    "\t\t\t}\n",
    "\n",
    "\t\t}\n",
    "\n",
    "\t\tif (UpdatedClassWordCount.containsKey(clazz)) {\n",
    "\t\t\tfor (String key : map.keySet()) {\n",
    "\t\t\t\tif (UpdatedClassWordCount.get(clazz).containsKey(key)) {\n",
    "\t\t\t\t\tUpdatedClassWordCount.get(clazz).put(key, UpdatedClassWordCount.get(clazz).get(key) + map.get(key));\n",
    "\t\t\t\t} else {\n",
    "\t\t\t\t\tUpdatedClassWordCount.get(clazz).put(key, map.get(key));\n",
    "\t\t\t\t}\n",
    "\t\t\t}\n",
    "\t\t}\n",
    "\n",
    "        \n",
    "        \n",
    "        return clazz;\n",
    "    }\n",
    "}\n",
    "\n",
    "/**\n",
    " * Learner (or Builder) class for a naive Bayes classifier.\n",
    " */\n",
    "public class BayesianLearner {\n",
    "    // YOUR CODE HERE\n",
    "    \n",
    "    Set<String> uniqueWords = new HashSet<>();\n",
    "\tHashMap<String, Integer> classCount = new HashMap<String, Integer>();\n",
    "\tHashMap<String, BigDecimal> classProb = new HashMap<String, BigDecimal>();\n",
    "\tHashMap<String, HashMap<String, Integer>> classWordCount = new HashMap<String, HashMap<String, Integer>>();\n",
    "\tint totalCount = 0;\n",
    "\n",
    "\tpublic final static String URL_REGEX = \"((www\\\\.[\\\\s]+)|(https?://[^\\\\s]+))\";\n",
    "\tpublic final static String CONSECUTIVE_CHARS = \"([a-z])\\\\1{1,}\";\n",
    "\tpublic final static String STARTS_WITH_NUMBER = \"[1-9]\\\\s*(\\\\w+)\";\n",
    "\n",
    "    /**\n",
    "     * Constructor taking the set of classes the classifier should be able to\n",
    "     * distinguish.\n",
    "     */\n",
    "    public BayesianLearner(Set<String> classes) {\n",
    "        // YOUR CODE HERE\n",
    "        \n",
    "        for (String c : classes) {\n",
    "\t\t\tthis.classCount.put(c, 0);\n",
    "\t\t\tthis.classProb.put(c, BigDecimal.ZERO);\n",
    "\t\t}\n",
    "    }\n",
    "\n",
    "    /**\n",
    "     * The method used to learn the training examples. It takes the name of the\n",
    "     * class as well as the text of the training document.\n",
    "     */\n",
    "    public void learnExample(String clazz, String text) {\n",
    "        // YOUR CODE HERE\n",
    "        totalCount++;\n",
    "\t\t// line = line.toLowerCase().replaceAll(\"[^a-z0-9\\\\s]\",\"\");\n",
    "\n",
    "\t\ttext = preprocess(text);\n",
    "\t\tString[] words = text.toLowerCase().split(\"[^a-z0-9']+\");\n",
    "\n",
    "\t\tif (classWordCount.containsKey(clazz)) {\n",
    "\t\t\t// HashMap<String, Integer> temp = classWordCount.get(clazz);\n",
    "\t\t\t// classWordCount.put(clazz, wordCount);\n",
    "\n",
    "\t\t\tHashMap<String, Integer> temp = classWordCount.get(clazz);\n",
    "\t\t\tfor (String c : words) {\n",
    "\t\t\t\tuniqueWords.add(c);\n",
    "\t\t\t\tif (temp.containsKey(c)) {\n",
    "\t\t\t\t\tint val = temp.get(c);\n",
    "\t\t\t\t\tval++;\n",
    "\t\t\t\t\ttemp.put(c, val);\n",
    "\t\t\t\t} else {\n",
    "\t\t\t\t\ttemp.put(c, 1);\n",
    "\t\t\t\t}\n",
    "\n",
    "\t\t\t}\n",
    "\n",
    "\t\t\tclassWordCount.put(clazz, temp);\n",
    "\n",
    "\t\t} else {\n",
    "\t\t\tHashMap<String, Integer> wordCount = new HashMap<String, Integer>();\n",
    "\t\t\tfor (String c : words) {\n",
    "\t\t\t\tuniqueWords.add(c);\n",
    "\t\t\t\tif (wordCount.containsKey(c)) {\n",
    "\t\t\t\t\tint val = wordCount.get(c);\n",
    "\t\t\t\t\tval++;\n",
    "\t\t\t\t\twordCount.put(c, val);\n",
    "\t\t\t\t} else {\n",
    "\t\t\t\t\twordCount.put(c, 1);\n",
    "\t\t\t\t}\n",
    "\n",
    "\t\t\t}\n",
    "\t\t\tclassWordCount.put(clazz, wordCount);\n",
    "\t\t}\n",
    "\n",
    "\t\t// updating class count based on input clazz\n",
    "\t\tif (classCount.containsKey(clazz)) {\n",
    "\t\t\tint val = classCount.get(clazz);\n",
    "\n",
    "\t\t\tval++;\n",
    "\t\t\t// System.out.println(\"value of \"+clazz+ \" is \"+ val);\n",
    "\t\t\tclassCount.put(clazz, val);\n",
    "\t\t} else {\n",
    "\t\t\tclassCount.put(clazz, 0);\n",
    "\t\t}\n",
    "\n",
    "    }\n",
    "    \n",
    "    public String preprocess(String text) {\n",
    "\n",
    "\t\ttext = text.replaceAll(STARTS_WITH_NUMBER, \"\");\n",
    "\n",
    "\t\t// text = text.replaceAll(\"@([^\\\\s]+)\", \"\");\n",
    "\t\ttext = text.replaceAll(\"[^\\\\s\\\\w']*\", \"\");\n",
    "\t\ttext = text.replaceAll(\"(\\\\bthe\\\\b)*\", \"\");\n",
    "\t\ttext = text.replaceAll(\"(\\\\band\\\\b)*\", \"\");\n",
    "\t\ttext = text.replaceAll(\"(\\\\ba\\\\b)*\", \"\");\n",
    "\t\ttext = text.replaceAll(\"(\\\\bis\\\\b)*\", \"\");\n",
    "\t\ttext = text.replaceAll(\"(\\\\bits\\\\b)*\", \"\");\n",
    "\t\ttext = text.replaceAll(\"(\\\\bfrom\\\\b)*\", \"\");\n",
    "\t\ttext = text.replaceAll(\"(\\\\bit\\\\b)*\", \"\");\n",
    "\t\ttext = text.replaceAll(\"(\\\\bfor\\\\b)*\", \"\");\n",
    "\t\ttext = text.replaceAll(\"(\\\\bin\\\\b)*\", \"\");\n",
    "\t\ttext = text.replaceAll(\"(\\\\bto\\\\b)*\", \"\");\n",
    "\t\ttext = text.replaceAll(\"(\\\\bof\\\\b)*\", \"\");\n",
    "\t\ttext = text.replaceAll(\"(\\\\bhas\\\\b)*\", \"\");\n",
    "\t\ttext = text.replaceAll(\"(\\\\bhad\\\\b)*\", \"\");\n",
    "\t\ttext = text.replaceAll(\"(\\\\bhave\\\\b)*\", \"\");\n",
    "\t\ttext = text.replaceAll(\"(\\\\bwas\\\\b)*\", \"\");\n",
    "\t\ttext = text.replaceAll(\"(\\\\bare\\\\b)*\", \"\");\n",
    "\t\ttext = text.replaceAll(\"(\\\\bat\\\\b)*\", \"\");\n",
    "\t\ttext = text.replaceAll(\"([0-9]+)*\", \"\");\n",
    "\n",
    "\t\treturn text;\n",
    "\t}\n",
    "\n",
    "    /**\n",
    "     * Creates a BayesianClassifier instance based on the statistics gathered from\n",
    "     * the training example.\n",
    "     */\n",
    "    public BayesianClassifier createClassifier() {\n",
    "        BayesianClassifier classifier = null;\n",
    "        // YOUR CODE HERE\n",
    "        \n",
    "        for (String key : this.classCount.keySet()) {\n",
    "\n",
    "\t\t\tBigDecimal value = (new BigDecimal(classCount.get(key))).divide(new BigDecimal(totalCount),\n",
    "\t\t\t\t\tMathContext.DECIMAL128);\n",
    "\t\t\tthis.classProb.put(key, value);\n",
    "\t\t}\n",
    "\n",
    "\t\tclassifier = new BayesianClassifier(this.classProb, this.classWordCount, this.classCount, this.totalCount,\n",
    "\t\t\t\tthis.uniqueWords);\n",
    "        \n",
    "        return classifier;\n",
    "    }\n",
    "}\n",
    "// This line should make sure that compile errors are directly identified when executing this cell\n",
    "// (the line itself does not produce any meaningful result)\n",
    "new BayesianLearner(new HashSet<>(Arrays.asList(\"good\",\"bad\")));\n",
    "System.out.println(\"compiled\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "4e9c819c081918a6fde3b4ba21898440",
     "grade": false,
     "grade_id": "cell-markdown-evaluation",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Evaluation\n",
    "\n",
    "- Run the following cell to test your implementation.\n",
    "- You can ignore the cells afterwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "0aa71148dd6b4d8a9c66d3ed77a548d1",
     "grade": true,
     "grade_id": "cell-autograde-visible",
     "locked": true,
     "points": 0,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Simple example corpus ----------\n",
      "Training corpus size: 5\n",
      "Eval. corpus size   : 3\n",
      "Training took       : 12ms\n",
      "Classification took : 8ms\n",
      "Baseline classifiers: \n",
      "Always literature   : 0.33333\n",
      "Always chess        : 0.33333\n",
      "Always history      : 0.33333\n",
      "Random guesser      : 0.33333\n",
      "Your solution       : 1.00000 (3 tp, 0 errors)\n",
      "Test successfully completed.\n",
      "\n",
      "---------- Larger example corpus ----------\n",
      "Training corpus size: 750\n",
      "Eval. corpus size   : 260\n",
      "Training took       : 1736ms\n",
      "Classification took : 1146ms\n",
      "Baseline classifiers: \n",
      "Always gold         : 0.03462\n",
      "Always money-fx     : 0.19231\n",
      "Always trade        : 0.16923\n",
      "Always interest     : 0.11538\n",
      "Always coffee       : 0.06154\n",
      "Always money-supply : 0.10000\n",
      "Always ship         : 0.05000\n",
      "Always sugar        : 0.06538\n",
      "Always crude        : 0.21154\n",
      "Random guesser      : 0.11111\n",
      "Your solution       : 0.85769 (223 tp, 37 errors)\n",
      "  Wrong classifications are:\n",
      "    id=5 expected=money-fx result=interest\n",
      "    id=10 expected=money-supply result=interest\n",
      "    id=39 expected=trade result=money-fx\n",
      "    id=43 expected=ship result=crude\n",
      "    id=46 expected=money-fx result=trade\n",
      "    id=55 expected=ship result=crude\n",
      "    id=56 expected=money-fx result=interest\n",
      "    id=61 expected=money-fx result=interest\n",
      "    id=62 expected=ship result=trade\n",
      "    id=90 expected=ship result=coffee\n",
      "    id=96 expected=money-fx result=interest\n",
      "    id=112 expected=gold result=interest\n",
      "    id=131 expected=gold result=interest\n",
      "    id=132 expected=money-fx result=interest\n",
      "    id=140 expected=money-supply result=interest\n",
      "    id=151 expected=money-fx result=interest\n",
      "    id=153 expected=ship result=crude\n",
      "    id=164 expected=money-fx result=interest\n",
      "    id=173 expected=ship result=crude\n",
      "    id=175 expected=trade result=money-fx\n",
      "    ...\n",
      "Test successfully completed.\n"
     ]
    }
   ],
   "source": [
    "%maven org.junit.jupiter:junit-jupiter-api:5.3.1\n",
    "import org.junit.jupiter.api.Assertions;\n",
    "import org.opentest4j.AssertionFailedError;\n",
    "import java.util.stream.Collectors;\n",
    "import org.apache.commons.io.FileUtils;\n",
    "import java.util.Map.Entry;\n",
    "\n",
    "/**\n",
    " * Simple method for reading classification examples from a file as a list of (class, text) pairs.\n",
    " */\n",
    "public static List<String[]> readClassData(String filename) throws IOException {\n",
    "    return FileUtils.readLines(new File(filename), \"utf-8\").stream().map(s -> s.split(\"\\t\"))\n",
    "            .filter(s -> s.length > 1).collect(Collectors.toList());\n",
    "}\n",
    "\n",
    "public static void checkClassifier(List<String[]> trainingCorpus, List<String[]> evaluationCorpus,\n",
    "        double minAccuracy) {\n",
    "    try {\n",
    "        System.out.print(\"Training corpus size: \");\n",
    "        System.out.println(trainingCorpus.size());\n",
    "        System.out.print(\"Eval. corpus size   : \");\n",
    "        System.out.println(evaluationCorpus.size());\n",
    "        // Determine the classes\n",
    "        Set<String> classes = Arrays.asList(trainingCorpus, evaluationCorpus).stream().flatMap(l -> l.stream())\n",
    "                .map(d -> d[0]).distinct().collect(Collectors.toSet());\n",
    "        // Determine the number of instances per class in the evaluation set\n",
    "        Map<String, Long> evalClassCounts = evaluationCorpus.stream()\n",
    "                .collect(Collectors.groupingBy(d -> d[0], Collectors.counting()));\n",
    "        for (String clazz : classes) {\n",
    "            if (!evalClassCounts.containsKey(clazz)) {\n",
    "                evalClassCounts.put(clazz, 0L);\n",
    "            }\n",
    "        }\n",
    "\n",
    "        // Determine the expected accuracies of the baselines\n",
    "        Map<String, Double> accForClassGuessers = new HashMap<>();\n",
    "        for (Entry<String, Long> e : evalClassCounts.entrySet()) {\n",
    "            accForClassGuessers.put(e.getKey(), e.getValue() / (double) evaluationCorpus.size());\n",
    "        }\n",
    "        double accRandomGuesser = 1.0 / accForClassGuessers.size();\n",
    "\n",
    "        // Train the classifier\n",
    "        long time1 = System.currentTimeMillis();\n",
    "        BayesianLearner learner = new BayesianLearner(classes);\n",
    "        for (String[] trainingExample : trainingCorpus) {\n",
    "            learner.learnExample(trainingExample[0], trainingExample[1]);\n",
    "        }\n",
    "        BayesianClassifier classifier = learner.createClassifier();\n",
    "        time1 = System.currentTimeMillis() - time1;\n",
    "        System.out.println(\"Training took       : \" + time1 + \"ms\");\n",
    "\n",
    "        // Classify the evaluation corpus\n",
    "        long time2 = System.currentTimeMillis();\n",
    "        int tp = 0, errors = 0, id = 0;\n",
    "        String result;\n",
    "        List<String[]> fpDetails = new ArrayList<>();\n",
    "        for (String[] evalExample : evaluationCorpus) {\n",
    "            result = classifier.classify(evalExample[1]);\n",
    "            if (evalExample[0].equals(result)) {\n",
    "                ++tp;\n",
    "            } else {\n",
    "                ++errors;\n",
    "                fpDetails.add(new String[] { Integer.toString(id), evalExample[0], result });\n",
    "            }\n",
    "            ++id;\n",
    "        }\n",
    "        time2 = System.currentTimeMillis() - time2;\n",
    "        System.out.println(\"Classification took : \" + time2 + \"ms\");\n",
    "        double accuracy = tp / (double) (tp + errors);\n",
    "\n",
    "        System.out.println(\"Baseline classifiers: \");\n",
    "        for (Entry<String, Double> baseResult : accForClassGuessers.entrySet()) {\n",
    "            System.out.println(String.format(\"Always %-13s: %-7.5f\", baseResult.getKey(), baseResult.getValue()));\n",
    "        }\n",
    "        System.out.println(String.format(\"Random guesser      : %-7.5f\", accRandomGuesser));\n",
    "        System.out.println(String.format(\"Your solution       : %-7.5f (%d tp, %d errors)\", accuracy, tp, errors));\n",
    "        if (fpDetails.size() > 0) {\n",
    "            System.out.println(\"  Wrong classifications are:\");\n",
    "            for (int i = 0; i < Math.min(fpDetails.size(), 20); ++i) {\n",
    "                System.out.print(\"    id=\");\n",
    "                System.out.print(fpDetails.get(i)[0]);\n",
    "                System.out.print(\" expected=\");\n",
    "                System.out.print(fpDetails.get(i)[1]);\n",
    "                System.out.print(\" result=\");\n",
    "                System.out.println(fpDetails.get(i)[2]);\n",
    "            }\n",
    "            if (fpDetails.size() > 20) {\n",
    "                System.out.println(\"    ...\");\n",
    "            }\n",
    "        }\n",
    "\n",
    "        // Make sure that the students solution is better than all baselines\n",
    "        for (Entry<String, Double> baseResult : accForClassGuessers.entrySet()) {\n",
    "            if (baseResult.getValue() >= accuracy) {\n",
    "                StringBuilder builder = new StringBuilder();\n",
    "                builder.append(\"Your solution is not better than a classifier that always chooses the \\\"\");\n",
    "                builder.append(baseResult.getKey());\n",
    "                builder.append(\"\\\" class.\");\n",
    "                Assertions.fail(builder.toString());\n",
    "            }\n",
    "        }\n",
    "        if (accRandomGuesser >= accuracy) {\n",
    "            Assertions.fail(\"Your solution is not better than a random guesser.\");\n",
    "        }\n",
    "        if ((minAccuracy > 0) && (minAccuracy > accuracy)) {\n",
    "            Assertions.fail(\"Your solution did not reach the expected accuracy of \" + minAccuracy);\n",
    "        }\n",
    "        System.out.println(\"Test successfully completed.\");\n",
    "    } catch (AssertionFailedError e) {\n",
    "        throw e;\n",
    "    } catch (Throwable e) {\n",
    "        System.err.println(\"Your solution caused an unexpected error:\");\n",
    "        throw e;\n",
    "    }\n",
    "}\n",
    "\n",
    "System.out.println(\"---------- Simple example corpus ----------\");\n",
    "List<String[]> exampleCorpusTrain = Arrays.asList(\n",
    "        new String[] {\"chess\", \"white king, black rook, black queen, white pawn, black knight, white bishop.\" },\n",
    "        new String[] {\"history\", \"knight person granted honorary title knighthood\" },\n",
    "        new String[] {\"history\", \"knight order eligibility, knighthood, head of state, king, prelate, middle ages.\" },\n",
    "        new String[] {\"chess\", \"Defense knight pawn opening game opponent.\" },\n",
    "        new String[] {\"literature\", \"Knights Round Table. King Arthur. literary cycle Matter of Britain.\"}\n",
    "        );\n",
    "List<String[]> exampleCorpusTest = Arrays.asList(\n",
    "        new String[] {\"history\", \"Knighthood Middle Ages.\" },\n",
    "        new String[] {\"chess\", \"player king knight opponent king checkmate game draw.\" },\n",
    "        // document with unknown words\n",
    "        new String[] {\"literature\", \"britain king arthur. Sir Galahad.\" }\n",
    "        );\n",
    "checkClassifier(exampleCorpusTrain, exampleCorpusTest, 0);\n",
    "\n",
    "System.out.println();\n",
    "System.out.println(\"---------- Larger example corpus ----------\");\n",
    "List<String[]> classificationData =readClassData(\"/srv/distribution/single-class-train.tsv\");\n",
    "checkClassifier(classificationData.subList(0, 750), classificationData.subList(750, classificationData.size()), 0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "fc4723f8815725c44713410c8d9ce586",
     "grade": true,
     "grade_id": "cell-autograde-1",
     "locked": true,
     "points": 4,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "// Ignore this cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "2280a65ff154fb7d12936e76235be051",
     "grade": true,
     "grade_id": "cell-autograde-2",
     "locked": true,
     "points": 3,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "// Ignore this cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "0ba1b93c7dc47996a5c81821c0c7c5cd",
     "grade": true,
     "grade_id": "cell-autograde-3",
     "locked": true,
     "points": 3,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "// Ignore this cell"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Java",
   "language": "java",
   "name": "java"
  },
  "language_info": {
   "codemirror_mode": "java",
   "file_extension": ".java",
   "mimetype": "text/x-java-source",
   "name": "Java",
   "pygments_lexer": "java",
   "version": "11.0.1+13-LTS"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
