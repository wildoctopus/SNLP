{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "6c947a87fd9deca67875c65ce1a63424",
     "grade": false,
     "grade_id": "cell-markdown-task",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Exercise 2 - Naive Bayes Multilabel Classification\n",
    "(10 points)\n",
    "\n",
    "Implement a Naive Bayes classifier which is able to assign multiple classes to a single document by finalizing the two given classes. The `MultiLabelLearner` class acts like a builder for the `MultiLabelClassifier` instances. That means that the learner gets the number of classes during its creation and the `learnExample` method of the learner is called once for each document of the training set. Internally, the learner should gather all statistics that are necessary for the classifier when processing the training examples.\n",
    "After the learner saw all training documents, the `createClassifier` method is called which creates an instance of the `MultiLabelClassifier` class and initializes it with the statistics gathered before. \n",
    "The classification itself is carried out by the `classify` method which takes an unknown document and assigns it a set of classes learned before.\n",
    "\n",
    "#### Hints\n",
    "\n",
    "- Please do not forget to preprocess your documents. What exactly the preprocessing does is up to you.\n",
    "- The classification should be based on the naive Bayes classification. You may want to reuse code from exercise 1.\n",
    "- In our datasets, each document has *at least one* class. You may want to take this information into account.\n",
    "- The evaluation will use micro precision, micro recall and micro F1-measure (also named or F1-score).\n",
    "- The evaluation in the hidden tests has three stages. \n",
    "  1. Your solution will get 4 points as soon as it is better than the baselines. The baselines are:\n",
    "     - For each class, a classifier that always returns this class.\n",
    "     - A random guesser that returns a random class.\n",
    "  2. If your solution has an F1-score >= 0.7, you will get 3 more points.\n",
    "  3. If your solution has an F1-score >= 0.8, you will get 3 more points.\n",
    "- You can download the [multi-class-train.tsv](https://hobbitdata.informatik.uni-leipzig.de/teaching/SNLP/classification/multi-class-train.tsv) file. It comprises one document per line. The first part comprises the classes (separated with a `\", \"` string), followed by a tab character (`\\t`). The remaining content of the line is the text of the document.\n",
    "\n",
    "#### Notes\n",
    "\n",
    "- Do not add additional external libraries.\n",
    "- Interface\n",
    "  - You can use _[TAB]_ for autocompletion and _[SHIFT]_+_[TAB]_ for code inspection.\n",
    "  - Use _Menu_ -> _View_ -> _Toggle Line Numbers_ for debugging.\n",
    "  - Check _Menu_ -> _Help_ -> _Keyboard Shortcuts_.\n",
    "- Finish\n",
    "  - Save your solution by clicking on the _disk icon_.\n",
    "  - Finally, choose _Menu_ -> _File_ -> _Close and Halt_.\n",
    "  - Do not forget to _Submit_ your solution in the _Assignments_ view."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "55e995d0be52a1c40c779d8e4c3e0ffb",
     "grade": false,
     "grade_id": "cell-code",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compiled\n"
     ]
    }
   ],
   "source": [
    "// YOUR CODE HERE\n",
    "\n",
    "\n",
    "public class BayesianClassifier {\n",
    "\t// YOUR CODE HERE\n",
    "\tSet<String> uniqueWords = null;\n",
    "\tHashMap<String, Integer> updatedClassCount = null;\n",
    "\tHashMap<String, BigDecimal> updatedClassProb = null;\n",
    "\tHashMap<String, HashMap<String, Integer>> UpdatedClassWordCount = null;\n",
    "\tint globalTotalCount = 0;\n",
    "\n",
    "\tHashMap<String, Double> classProbabilites = new HashMap<>();\n",
    "\n",
    "\tpublic final static String STARTS_WITH_NUMBER = \"[1-9]\\\\s*(\\\\w+)\";\n",
    "\n",
    "\tBayesianClassifier(HashMap<String, BigDecimal> classProb, HashMap<String, HashMap<String, Integer>> classWordCount,\n",
    "\t\t\tHashMap<String, Integer> classCount, int totalCount, Set<String> uniqueWords) {\n",
    "\t\tthis.updatedClassCount = classCount;\n",
    "\t\tthis.updatedClassProb = classProb;\n",
    "\t\tthis.UpdatedClassWordCount = classWordCount;\n",
    "\t\tthis.globalTotalCount = totalCount;\n",
    "\t\tthis.uniqueWords = uniqueWords;\n",
    "\n",
    "\t}\n",
    "\n",
    "\tpublic String preprocess(String text) {\n",
    "\n",
    "\t\t\n",
    "\t\t\n",
    "\t\ttext = text.replaceAll(STARTS_WITH_NUMBER, \"\");\n",
    "\t\t\n",
    "\t\t// text = text.replaceAll(\"@([^\\\\s]+)\", \"\");\n",
    "\t\ttext = text.replaceAll(\"[^\\\\s\\\\w']*\", \"\");\n",
    "\t\ttext = text.replaceAll(\"(\\\\bthe\\\\b)*\", \"\");\n",
    "\t\ttext = text.replaceAll(\"(\\\\band\\\\b)*\", \"\");\n",
    "\t\ttext = text.replaceAll(\"(\\\\ba\\\\b)*\", \"\");\n",
    "\t\ttext = text.replaceAll(\"(\\\\bis\\\\b)*\", \"\");\n",
    "\t\ttext = text.replaceAll(\"(\\\\bits\\\\b)*\", \"\");\n",
    "\t\ttext = text.replaceAll(\"(\\\\bfrom\\\\b)*\", \"\");\n",
    "\t\ttext = text.replaceAll(\"(\\\\bit\\\\b)*\", \"\");\n",
    "\t\ttext = text.replaceAll(\"(\\\\bfor\\\\b)*\", \"\");\n",
    "\t\ttext = text.replaceAll(\"(\\\\bin\\\\b)*\", \"\");\n",
    "\t\ttext = text.replaceAll(\"(\\\\bto\\\\b)*\", \"\");\n",
    "\t\ttext = text.replaceAll(\"(\\\\bof\\\\b)*\", \"\");\n",
    "\t\ttext = text.replaceAll(\"(\\\\bhas\\\\b)*\", \"\");\n",
    "\t\ttext = text.replaceAll(\"(\\\\bhad\\\\b)*\", \"\");\n",
    "\t\ttext = text.replaceAll(\"(\\\\bhave\\\\b)*\", \"\");\n",
    "\t\ttext = text.replaceAll(\"(\\\\bwas\\\\b)*\", \"\");\n",
    "\t\ttext = text.replaceAll(\"(\\\\bare\\\\b)*\", \"\");\n",
    "\t\ttext = text.replaceAll(\"(\\\\bat\\\\b)*\", \"\");\n",
    "\t\ttext = text.replaceAll(\"([0-9]+)*\", \"\");\n",
    "\t\t\n",
    "\t\treturn text;\n",
    "\t}\n",
    "\n",
    "\t/**\n",
    "\t * Classifies the given document and returns the class name.\n",
    "\t */\n",
    "\tpublic String classify(String text) {\n",
    "\t\tString clazz = null;\n",
    "\n",
    "\t\ttext = preprocess(text);\n",
    "\t\tString[] words = text.toLowerCase().split(\"[^a-z0-9']+\");\n",
    "\t\tHashMap<String, Integer> map = new HashMap<String, Integer>();\n",
    "\n",
    "\t\tint uniqueWordsSize = this.uniqueWords.size();\n",
    "\n",
    "\t\tfor (String word : words) {\n",
    "\n",
    "\t\t\tthis.uniqueWords.add(word);\n",
    "\n",
    "\t\t\tif (map.containsKey(word)) {\n",
    "\t\t\t\tint value = map.get(word);\n",
    "\t\t\t\tvalue++;\n",
    "\t\t\t\tmap.put(word, value);\n",
    "\t\t\t} else {\n",
    "\t\t\t\tmap.put(word, 1);\n",
    "\t\t\t}\n",
    "\n",
    "\t\t}\n",
    "\n",
    "\t\tBigDecimal minimum = BigDecimal.ZERO;\n",
    "\n",
    "\t\tfor (String key : this.updatedClassCount.keySet()) {\n",
    "\t\t\tBigDecimal finalProbability = BigDecimal.ONE;\n",
    "\n",
    "\t\t\tBigDecimal classProb = BigDecimal.ZERO;\n",
    "\n",
    "\t\t\tif (updatedClassProb.containsKey(key)) {\n",
    "\t\t\t\t// System.out.println(\"Class \"+key+ \" has probability\n",
    "\t\t\t\t// \"+updatedClassProb.get(key));\n",
    "\t\t\t\tclassProb = updatedClassProb.get(key);\n",
    "\t\t\t}\n",
    "\n",
    "\t\t\tHashMap<String, Integer> temp = UpdatedClassWordCount.get(key);\n",
    "\t\t\t// System.out.println(\"Temp \"+temp);\n",
    "\t\t\tint totalWordsInHapMapForThatClass = 0;\n",
    "\n",
    "\t\t\tfor (int value : temp.values()) {\n",
    "\t\t\t\ttotalWordsInHapMapForThatClass += value;\n",
    "\t\t\t}\n",
    "\n",
    "\t\t\tfor (String k : map.keySet()) {\n",
    "\t\t\t\tBigDecimal wordFrequency = BigDecimal.ZERO;\n",
    "\n",
    "\t\t\t\tif (temp.containsKey(k)) {\n",
    "\t\t\t\t\twordFrequency = new BigDecimal(temp.get(k));\n",
    "\t\t\t\t\t// System.out.println(\" word frequ for word \"+k+\" is\n",
    "\t\t\t\t\t// \"+wordFreq);\n",
    "\t\t\t\t\tBigDecimal denominator = new BigDecimal(totalWordsInHapMapForThatClass)\n",
    "\t\t\t\t\t\t\t.add(new BigDecimal(uniqueWordsSize));\n",
    "\t\t\t\t\tBigDecimal probByClass = (wordFrequency.add(BigDecimal.ONE)).divide(denominator,\n",
    "\t\t\t\t\t\t\tMathContext.DECIMAL128);\n",
    "\n",
    "\t\t\t\t\tBigDecimal power = probByClass.pow(map.get(k),MathContext.DECIMAL128);\n",
    "\t\t\t\t\tfinalProbability = finalProbability.multiply(power,MathContext.DECIMAL128);\n",
    "\n",
    "\t\t\t\t} else {\n",
    "\n",
    "\t\t\t\t\tBigDecimal denominator = (new BigDecimal(totalWordsInHapMapForThatClass))\n",
    "\t\t\t\t\t\t\t.add(new BigDecimal(uniqueWordsSize));\n",
    "\t\t\t\t\tBigDecimal probByClass = (BigDecimal.ONE).divide(denominator, MathContext.DECIMAL128);\n",
    "\n",
    "\t\t\t\t\tBigDecimal power = probByClass.pow(map.get(k),MathContext.DECIMAL128);\n",
    "\t\t\t\t\tfinalProbability = finalProbability.multiply(power,MathContext.DECIMAL128);\n",
    "\n",
    "\t\t\t\t}\n",
    "\n",
    "\t\t\t}\n",
    "\n",
    "\t\t\tfinalProbability = finalProbability.multiply(classProb,MathContext.DECIMAL128);\n",
    "\n",
    "\t\t\tif (finalProbability.compareTo(minimum) == 1) {\n",
    "\t\t\t\tclazz = key;\n",
    "\t\t\t\tminimum = finalProbability;\n",
    "\t\t\t}\n",
    "\n",
    "\t\t}\n",
    "\n",
    "\t\t// update ClassCounr Map\n",
    "\t\tglobalTotalCount++;\n",
    "\n",
    "\t\tif (updatedClassCount.containsKey(clazz)) {\n",
    "\t\t\tint value = updatedClassCount.get(clazz);\n",
    "\t\t\tvalue++;\n",
    "\t\t\tupdatedClassCount.put(clazz, value);\n",
    "\n",
    "\t\t\tfor (String key : updatedClassCount.keySet()) {\n",
    "\t\t\t\tBigDecimal value1 = (new BigDecimal(updatedClassCount.get(key)))\n",
    "\t\t\t\t\t\t.divide(new BigDecimal(globalTotalCount), MathContext.DECIMAL128);\n",
    "\t\t\t\tupdatedClassProb.put(key, value1);\n",
    "\t\t\t}\n",
    "\n",
    "\t\t}\n",
    "\n",
    "\t\tif (UpdatedClassWordCount.containsKey(clazz)) {\n",
    "\t\t\tfor (String key : map.keySet()) {\n",
    "\t\t\t\tif (UpdatedClassWordCount.get(clazz).containsKey(key)) {\n",
    "\t\t\t\t\tUpdatedClassWordCount.get(clazz).put(key, UpdatedClassWordCount.get(clazz).get(key) + map.get(key));\n",
    "\t\t\t\t} else {\n",
    "\t\t\t\t\tUpdatedClassWordCount.get(clazz).put(key, map.get(key));\n",
    "\t\t\t\t}\n",
    "\t\t\t}\n",
    "\t\t}\n",
    "\n",
    "\t\treturn clazz;\n",
    "\t}\n",
    "}\n",
    "\n",
    "\n",
    "/**\n",
    " * Learner (or Builder) class for a naive Bayes classifier.\n",
    " */\n",
    "/**\n",
    " * Learner (or Builder) class for a naive Bayes classifier.\n",
    " */\n",
    "public class BayesianLearner {\n",
    "\t// YOUR CODE HERE\n",
    "\tSet<String> uniqueWords = new HashSet<>();\n",
    "\tHashMap<String, Integer> classCount = new HashMap<String, Integer>();\n",
    "\tHashMap<String, BigDecimal> classProb = new HashMap<String, BigDecimal>();\n",
    "\tHashMap<String, HashMap<String, Integer>> classWordCount = new HashMap<String, HashMap<String, Integer>>();\n",
    "\tint totalCount = 0;\n",
    "\n",
    "\t\n",
    "\tpublic final static String STARTS_WITH_NUMBER = \"[1-9]\\\\s*(\\\\w+)\";\n",
    "\n",
    "\t/**\n",
    "\t * Constructor taking the set of classes the classifier should be able to\n",
    "\t * distinguish.\n",
    "\t */\n",
    "\tpublic BayesianLearner(Set<String> classes) {\n",
    "\t\t// YOUR CODE HERE\n",
    "\t\tfor (String c : classes) {\n",
    "\t\t\tthis.classCount.put(c, 0);\n",
    "\t\t\tthis.classProb.put(c, BigDecimal.ZERO);\n",
    "\t\t}\n",
    "\n",
    "\t}\n",
    "\n",
    "\t/**\n",
    "\t * The method used to learn the training examples. It takes the name of the\n",
    "\t * class as well as the text of the training document.\n",
    "\t */\n",
    "\tpublic void learnExample(String clazz, String text) {\n",
    "\t\t// YOUR CODE HERE\n",
    "\t\ttotalCount++;\n",
    "\t\t// line = line.toLowerCase().replaceAll(\"[^a-z0-9\\\\s]\",\"\");\n",
    "\n",
    "\t\ttext = preprocess(text);\n",
    "\t\tString[] words = text.toLowerCase().split(\"[^a-z0-9']+\");\n",
    "\n",
    "\t\tif (classWordCount.containsKey(clazz)) {\n",
    "\t\t\t// HashMap<String, Integer> temp = classWordCount.get(clazz);\n",
    "\t\t\t// classWordCount.put(clazz, wordCount);\n",
    "\n",
    "\t\t\tHashMap<String, Integer> temp = classWordCount.get(clazz);\n",
    "\t\t\tfor (String c : words) {\n",
    "\t\t\t\tuniqueWords.add(c);\n",
    "\t\t\t\tif (temp.containsKey(c)) {\n",
    "\t\t\t\t\tint val = temp.get(c);\n",
    "\t\t\t\t\tval++;\n",
    "\t\t\t\t\ttemp.put(c, val);\n",
    "\t\t\t\t} else {\n",
    "\t\t\t\t\ttemp.put(c, 1);\n",
    "\t\t\t\t}\n",
    "\n",
    "\t\t\t}\n",
    "\n",
    "\t\t\tclassWordCount.put(clazz, temp);\n",
    "\n",
    "\t\t} else {\n",
    "\t\t\tHashMap<String, Integer> wordCount = new HashMap<String, Integer>();\n",
    "\t\t\tfor (String c : words) {\n",
    "\t\t\t\tuniqueWords.add(c);\n",
    "\t\t\t\tif (wordCount.containsKey(c)) {\n",
    "\t\t\t\t\tint val = wordCount.get(c);\n",
    "\t\t\t\t\tval++;\n",
    "\t\t\t\t\twordCount.put(c, val);\n",
    "\t\t\t\t} else {\n",
    "\t\t\t\t\twordCount.put(c, 1);\n",
    "\t\t\t\t}\n",
    "\n",
    "\t\t\t}\n",
    "\t\t\tclassWordCount.put(clazz, wordCount);\n",
    "\t\t}\n",
    "\n",
    "\t\t// updating class count based on input clazz\n",
    "\t\tif (classCount.containsKey(clazz)) {\n",
    "\t\t\tint val = classCount.get(clazz);\n",
    "\n",
    "\t\t\tval++;\n",
    "\t\t\t// System.out.println(\"value of \"+clazz+ \" is \"+ val);\n",
    "\t\t\tclassCount.put(clazz, val);\n",
    "\t\t} else {\n",
    "\t\t\tclassCount.put(clazz, 0);\n",
    "\t\t}\n",
    "\n",
    "\t}\n",
    "\n",
    "\tpublic String preprocess(String text) {\n",
    "\n",
    "\t\t  \n",
    "\t\t//text = text.replaceAll(STARTS_WITH_NUMBER, \"\");\n",
    "\t\t\n",
    "\t\ttext = text.replaceAll(STARTS_WITH_NUMBER, \"\");\n",
    "\t\t\n",
    "\n",
    "\t\t// text = text.replaceAll(\"@([^\\\\s]+)\", \"\");\n",
    "\t\ttext = text.replaceAll(\"[^\\\\s\\\\w']*\", \"\");\n",
    "\t\ttext = text.replaceAll(\"(\\\\bthe\\\\b)*\", \"\");\n",
    "\t\ttext = text.replaceAll(\"(\\\\band\\\\b)*\", \"\");\n",
    "\t\ttext = text.replaceAll(\"(\\\\ba\\\\b)*\", \"\");\n",
    "\t\ttext = text.replaceAll(\"(\\\\bis\\\\b)*\", \"\");\n",
    "\t\ttext = text.replaceAll(\"(\\\\bits\\\\b)*\", \"\");\n",
    "\t\ttext = text.replaceAll(\"(\\\\bfrom\\\\b)*\", \"\");\n",
    "\t\ttext = text.replaceAll(\"(\\\\bit\\\\b)*\", \"\");\n",
    "\t\ttext = text.replaceAll(\"(\\\\bfor\\\\b)*\", \"\");\n",
    "\t\ttext = text.replaceAll(\"(\\\\bin\\\\b)*\", \"\");\n",
    "\t\ttext = text.replaceAll(\"(\\\\bto\\\\b)*\", \"\");\n",
    "\t\ttext = text.replaceAll(\"(\\\\bof\\\\b)*\", \"\");\n",
    "\t\ttext = text.replaceAll(\"(\\\\bhas\\\\b)*\", \"\");\n",
    "\t\ttext = text.replaceAll(\"(\\\\bhad\\\\b)*\", \"\");\n",
    "\t\ttext = text.replaceAll(\"(\\\\bhave\\\\b)*\", \"\");\n",
    "\t\ttext = text.replaceAll(\"(\\\\bwas\\\\b)*\", \"\");\n",
    "\t\ttext = text.replaceAll(\"(\\\\bare\\\\b)*\", \"\");\n",
    "\t\ttext = text.replaceAll(\"(\\\\bat\\\\b)*\", \"\");\n",
    "\t\ttext = text.replaceAll(\"([0-9]+)*\", \"\");\n",
    "\t\t\n",
    "\t\t\n",
    "\n",
    "\t\treturn text;\n",
    "\t}\n",
    "\n",
    "\t/**\n",
    "\t * Creates a BayesianClassifier instance based on the statistics gathered\n",
    "\t * from the training example.\n",
    "\t */\n",
    "\tpublic BayesianClassifier createClassifier() {\n",
    "\t\tBayesianClassifier classifier = null;\n",
    "\t\t// YOUR CODE HERE\n",
    "\n",
    "\t\tfor (String key : this.classCount.keySet()) {\n",
    "\n",
    "\t\t\tBigDecimal value = (new BigDecimal(classCount.get(key))).divide(new BigDecimal(totalCount),\n",
    "\t\t\t\t\tMathContext.DECIMAL128);\n",
    "\t\t\tthis.classProb.put(key, value);\n",
    "\t\t}\n",
    "\n",
    "\t\tclassifier = new BayesianClassifier(this.classProb, this.classWordCount, this.classCount, this.totalCount,\n",
    "\t\t\t\tthis.uniqueWords);\n",
    "\t\treturn classifier;\n",
    "\t}\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "/**\n",
    " * Classifier implementing naive Bayes classification for a multilabel\n",
    " * classification.\n",
    " */\n",
    "public class MultiLabelClassifier {\n",
    "    // YOUR CODE HERE\n",
    "    \n",
    "\tMap<String, BayesianLearner> learner = null;\n",
    "\tSet<String> totalClass = null;\n",
    "\tMap<String, BayesianClassifier> classifier = null;\n",
    "    \n",
    "    MultiLabelClassifier(Map<String, BayesianLearner> learner, Set<String> totalClass, Map<String, BayesianClassifier> classifier) {\n",
    "\t\tthis.learner = learner;\n",
    "\t\tthis.totalClass = totalClass;\n",
    "\t\tthis.classifier = classifier;\n",
    "\n",
    "\t}\n",
    "    \n",
    "   \n",
    "    /**\n",
    "     * Classifies the given document and returns the class names.\n",
    "     */\n",
    "    public Set<String> classify(String text) {\n",
    "        Set<String> results = null;\n",
    "        \n",
    "        results = new HashSet<String>();\n",
    "        for(String key:this.totalClass)\n",
    "        {\n",
    "        \t\n",
    "        \tBayesianClassifier bc = this.classifier.get(key);\n",
    "        \tString clazz = bc.classify(text);\n",
    "        \t\n",
    "        \tif(clazz == \"yes\")\n",
    "        \t{\n",
    "        \t\tresults.add(key);\n",
    "        \t}\n",
    "        \t\n",
    "        \t//MultiLabelClassifier mc = new MultiLabelClassifier(learner, totalClass);\n",
    "        \t\n",
    "        \t\n",
    "        }\n",
    "       \n",
    "        return results;\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "/**\n",
    " * Learner (or Builder) class for a naive Bayes multilabel classifier.\n",
    " */\n",
    "public class MultiLabelLearner {\n",
    "    // YOUR CODE HERE\n",
    "\n",
    "    Map<String, BayesianLearner> learner = new HashMap<String, BayesianLearner>();\n",
    "    Map<String, BayesianClassifier> classifier = new HashMap<String, BayesianClassifier>();\n",
    "    Set<String> totalClass = new HashSet<String>();\n",
    "   \n",
    "    /**\n",
    "     * Constructor taking the number of classes the classifier should be able to\n",
    "     * distinguish.\n",
    "     */\n",
    "    public MultiLabelLearner(Set<String> classes) {\n",
    "        // YOUR CODE HERE\n",
    "        Set<String> baseClass = new HashSet<String>();\n",
    "        this.totalClass = classes;\n",
    "        \n",
    "        baseClass.add(\"yes\");\n",
    "        baseClass.add(\"no\");\n",
    "        \n",
    "        for (String c : classes) {\n",
    "        \tlearner.put(c, new BayesianLearner(baseClass));\n",
    "\t\t}\n",
    "        \n",
    "    }\n",
    "\n",
    "    /**\n",
    "     * The method used to learn the training examples. It takes the names of the\n",
    "     * classes as well as the text of the training document.\n",
    "     */\n",
    "    public void learnExample(Set<String> classes, String text) {\n",
    "    \t\n",
    "    \tfor(String c:this.totalClass)\n",
    "    \t{\n",
    "    \t\tif(classes.contains(c))\n",
    "    \t\t{\n",
    "    \t\t\tBayesianLearner bl = learner.get(c);\n",
    "    \t\t\tbl.learnExample(\"yes\", text);\n",
    "    \t\t}\n",
    "    \t\telse\n",
    "    \t\t{\n",
    "    \t\t\tBayesianLearner bl = learner.get(c);\n",
    "    \t\t\tbl.learnExample(\"no\", text);\n",
    "    \t\t}\n",
    "    \t}\n",
    "    }\n",
    "\n",
    "    \n",
    "    \n",
    "    /**\n",
    "     * Creates a MultiLabelClassifier instance based on the statistics gathered from\n",
    "     * the training example.\n",
    "     */\n",
    "    public MultiLabelClassifier createClassifier() {\n",
    "        MultiLabelClassifier classifier = null;\n",
    "        \n",
    "        for (String key : this.totalClass) {\n",
    "        \tBayesianLearner bl = learner.get(key);\n",
    "        \tthis.classifier.put(key, bl.createClassifier());\n",
    "\t\t\t\n",
    "\t\t}\n",
    "\n",
    "\t\tclassifier = new MultiLabelClassifier(this.learner, this.totalClass, this.classifier);\n",
    "        \n",
    "        // YOUR CODE HERE\n",
    "        return classifier;\n",
    "    }\n",
    "}\n",
    "// This line should make sure that compile errors are directly identified when executing this cell\n",
    "// (the line itself does not produce any meaningful result)\n",
    "new MultiLabelLearner(new HashSet<>(Arrays.asList(\"good\",\"bad\")));\n",
    "System.out.println(\"compiled\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "4e9c819c081918a6fde3b4ba21898440",
     "grade": false,
     "grade_id": "cell-markdown-evaluation",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Evaluation\n",
    "\n",
    "- Run the following cell to test your implementation.\n",
    "- You can ignore the cells afterwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "b87b0ed1d8169d1568fc0fd9b15dc36c",
     "grade": true,
     "grade_id": "cell-autograde-visible",
     "locked": true,
     "points": 0,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Simple example corpus ----------\n",
      "Training corpus size: 5\n",
      "Eval. corpus size   : 3\n",
      "Training took       : 27ms\n",
      "Classification took : 12ms\n",
      "classifiers           precision    recall  f1-score\n",
      "Always game         :   0.66667   0.50000   0.57143\n",
      "Always chess        :   0.33333   0.25000   0.28571\n",
      "Always history      :   0.33333   0.25000   0.28571\n",
      "Your solution       :   0.80000   1.00000   0.88889 (4 tp, 4 tn, 1 fp, 0 fn)\n",
      "  Wrong classifications are:\n",
      "    id=2 expected=[game] result=[game, chess]\n",
      "    id=2 expected=[game] result=[chess]\n",
      "Test successfully completed.\n",
      "\n",
      "---------- Larger example corpus ----------\n",
      "Training corpus size: 600\n",
      "Eval. corpus size   : 195\n",
      "Training took       : 11410ms\n",
      "Classification took : 3850ms\n",
      "classifiers           precision    recall  f1-score\n",
      "Always money-fx     :   0.43590   0.29720   0.35343\n",
      "Always nat-gas      :   0.03077   0.02098   0.02495\n",
      "Always interest     :   0.10256   0.06993   0.08316\n",
      "Always corn         :   0.06667   0.04545   0.05405\n",
      "Always ship         :   0.16923   0.11538   0.13721\n",
      "Always wheat        :   0.08718   0.05944   0.07069\n",
      "Always dlr          :   0.12821   0.08741   0.10395\n",
      "Always grain        :   0.15385   0.10490   0.12474\n",
      "Always crude        :   0.29231   0.19930   0.23701\n",
      "Your solution       :   0.83178   0.93357   0.87974 (267 tp, 1415 tn, 54 fp, 19 fn)\n",
      "  Wrong classifications are:\n",
      "    id=5 expected=[corn, grain] result=[grain]\n",
      "    id=9 expected=[money-fx] result=[money-fx, dlr]\n",
      "    id=9 expected=[money-fx] result=[dlr]\n",
      "    id=13 expected=[nat-gas, crude] result=[crude]\n",
      "    id=22 expected=[money-fx, interest] result=[money-fx]\n",
      "    id=28 expected=[money-fx, interest] result=[money-fx, dlr]\n",
      "    id=28 expected=[money-fx, interest] result=[money-fx, dlr]\n",
      "    id=28 expected=[money-fx, interest] result=[dlr]\n",
      "    id=29 expected=[ship] result=[ship, crude]\n",
      "    id=29 expected=[ship] result=[crude]\n",
      "    id=33 expected=[money-fx] result=[money-fx, interest]\n",
      "    id=33 expected=[money-fx] result=[interest]\n",
      "    id=35 expected=[money-fx] result=[money-fx, interest, dlr]\n",
      "    id=35 expected=[money-fx] result=[money-fx, interest, dlr]\n",
      "    id=35 expected=[money-fx] result=[interest, dlr]\n",
      "    id=36 expected=[ship, crude] result=[ship]\n",
      "    id=45 expected=[money-fx] result=[money-fx, interest]\n",
      "    id=45 expected=[money-fx] result=[interest]\n",
      "    id=49 expected=[ship] result=[grain]\n",
      "    id=49 expected=[ship] result=[grain]\n",
      "    ...\n",
      "Test successfully completed.\n"
     ]
    }
   ],
   "source": [
    "%maven org.junit.jupiter:junit-jupiter-api:5.3.1\n",
    "import org.junit.jupiter.api.Assertions;\n",
    "import org.opentest4j.AssertionFailedError;\n",
    "import java.util.stream.Collectors;\n",
    "import java.util.Map.Entry;\n",
    "import org.apache.commons.io.FileUtils;\n",
    "import java.io.File;\n",
    "import java.io.IOException;\n",
    "\n",
    "/**\n",
    " * Simple structure to store the classes and the text of a document.\n",
    " */\n",
    "public class ClassifiedDocument {\n",
    "    public final Set<String> classes;\n",
    "    public final String text;\n",
    "    public ClassifiedDocument(Set<String> classes, String text) {\n",
    "        this.classes = classes;\n",
    "        this.text = text;\n",
    "    }\n",
    "}\n",
    "/**\n",
    " * Simple method for reading classification examples from a file as a list of (classes, text) pairs.\n",
    " */\n",
    "public static List<ClassifiedDocument> readClassData(String filename) throws IOException {\n",
    "    return FileUtils.readLines(new File(filename), \"utf-8\").stream().map(s -> s.split(\"\\t\"))\n",
    "            .filter(s -> s.length > 1)\n",
    "            .map(s -> new ClassifiedDocument(new HashSet<>(Arrays.asList(s[0].split(\", \"))), s[1]))\n",
    "            .collect(Collectors.toList());\n",
    "}\n",
    "\n",
    "public static void checkClassifier(List<ClassifiedDocument> trainingCorpus,\n",
    "        List<ClassifiedDocument> evaluationCorpus, double minF1Score) {\n",
    "    try {\n",
    "        System.out.print(\"Training corpus size: \");\n",
    "        System.out.println(trainingCorpus.size());\n",
    "        System.out.print(\"Eval. corpus size   : \");\n",
    "        System.out.println(evaluationCorpus.size());\n",
    "        // Determine the classes\n",
    "        Set<String> classes = Arrays.asList(trainingCorpus, evaluationCorpus).stream().flatMap(l -> l.stream())\n",
    "                .map(d -> d.classes).flatMap(c -> c.stream()).distinct().collect(Collectors.toSet());\n",
    "        // Determine the number of instances per class in the evaluation set\n",
    "        Map<String, Long> evalClassCounts = evaluationCorpus.stream().map(d -> d.classes).flatMap(c -> c.stream())\n",
    "                .collect(Collectors.groupingBy(c -> c, Collectors.counting()));\n",
    "        for (String clazz : classes) {\n",
    "            if (!evalClassCounts.containsKey(clazz)) {\n",
    "                evalClassCounts.put(clazz, 0L);\n",
    "            }\n",
    "        }\n",
    "        long expectedClassSum = evalClassCounts.entrySet().stream().mapToLong(e -> e.getValue()).sum();\n",
    "\n",
    "        // Determine the expected accuracies of the baselines\n",
    "        Map<String, double[]> f1ForClassGuessers = new HashMap<>();\n",
    "        for (Entry<String, Long> e : evalClassCounts.entrySet()) {\n",
    "            f1ForClassGuessers.put(e.getKey(), calcStats(e.getValue().intValue(),\n",
    "                    evaluationCorpus.size() - e.getValue().intValue(), (int) (expectedClassSum - e.getValue())));\n",
    "        }\n",
    "\n",
    "        // Train the classifier\n",
    "        long time1 = System.currentTimeMillis();\n",
    "        MultiLabelLearner learner = new MultiLabelLearner(classes);\n",
    "        for (ClassifiedDocument trainingExample : trainingCorpus) {\n",
    "            learner.learnExample(trainingExample.classes, trainingExample.text);\n",
    "        }\n",
    "        MultiLabelClassifier classifier = learner.createClassifier();\n",
    "        time1 = System.currentTimeMillis() - time1;\n",
    "        System.out.println(\"Training took       : \" + time1 + \"ms\");\n",
    "\n",
    "        // Classify the evaluation corpus\n",
    "        long time2 = System.currentTimeMillis();\n",
    "        Map<String, int[]> classCounts = new HashMap<>();\n",
    "        final int TP = 0, FP = 1, FN = 2, TN = 3;\n",
    "        for (String clazz : classes) {\n",
    "            classCounts.put(clazz, new int[4]);\n",
    "        }\n",
    "        int id = 0;\n",
    "        Set<String> result;\n",
    "        List<String[]> errorDetails = new ArrayList<>();\n",
    "        boolean added;\n",
    "        for (ClassifiedDocument evalExample : evaluationCorpus) {\n",
    "            added = false;\n",
    "            result = classifier.classify(evalExample.text);\n",
    "            String resultAsString = result.toString();\n",
    "            for (String clazz : classes) {\n",
    "                if (evalExample.classes.contains(clazz)) {\n",
    "                    if (result.contains(clazz)) {\n",
    "                        ++classCounts.get(clazz)[TP];\n",
    "                    } else {\n",
    "                        ++classCounts.get(clazz)[FN];\n",
    "                        if (!added) {\n",
    "                            errorDetails.add(new String[] { Integer.toString(id), evalExample.classes.toString(),\n",
    "                                    resultAsString });\n",
    "                        }\n",
    "                    }\n",
    "                } else {\n",
    "                    if (result.contains(clazz)) {\n",
    "                        ++classCounts.get(clazz)[FP];\n",
    "                        if (!added) {\n",
    "                            errorDetails.add(new String[] { Integer.toString(id), evalExample.classes.toString(),\n",
    "                                    resultAsString });\n",
    "                        }\n",
    "                    } else {\n",
    "                        ++classCounts.get(clazz)[TN];\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "            result.removeAll(evalExample.classes);\n",
    "            if ((result.size() > 0) && (!added)) {\n",
    "                errorDetails.add(\n",
    "                        new String[] { Integer.toString(id), evalExample.classes.toString(), result.toString() });\n",
    "            }\n",
    "            ++id;\n",
    "        }\n",
    "        time2 = System.currentTimeMillis() - time2;\n",
    "        System.out.println(\"Classification took : \" + time2 + \"ms\");\n",
    "        int counts[] = new int[4];\n",
    "        for (Entry<String, int[]> stats : classCounts.entrySet()) {\n",
    "            counts[0] += stats.getValue()[0];\n",
    "            counts[1] += stats.getValue()[1];\n",
    "            counts[2] += stats.getValue()[2];\n",
    "            counts[3] += stats.getValue()[3];\n",
    "        }\n",
    "        double solutionPerformance[] = calcStats(counts[TP], counts[FP], counts[FN]);\n",
    "\n",
    "        System.out.println(\"classifiers           precision    recall  f1-score\");\n",
    "        for (Entry<String, double[]> baseResult : f1ForClassGuessers.entrySet()) {\n",
    "            System.out.println(String.format(\"Always %-13s:   %-7.5f   %-7.5f   %-7.5f\", baseResult.getKey(),\n",
    "                    baseResult.getValue()[0], baseResult.getValue()[1], baseResult.getValue()[2]));\n",
    "        }\n",
    "        System.out.println(\n",
    "                String.format(\"Your solution       :   %-7.5f   %-7.5f   %-7.5f (%d tp, %d tn, %d fp, %d fn)\",\n",
    "                        solutionPerformance[0], solutionPerformance[1], solutionPerformance[2], counts[TP],\n",
    "                        counts[TN], counts[FP], counts[FN]));\n",
    "        if (errorDetails.size() > 0) {\n",
    "            System.out.println(\"  Wrong classifications are:\");\n",
    "            for (int i = 0; i < Math.min(errorDetails.size(), 20); ++i) {\n",
    "                System.out.print(\"    id=\");\n",
    "                System.out.print(errorDetails.get(i)[0]);\n",
    "                System.out.print(\" expected=\");\n",
    "                System.out.print(errorDetails.get(i)[1]);\n",
    "                System.out.print(\" result=\");\n",
    "                System.out.println(errorDetails.get(i)[2]);\n",
    "            }\n",
    "            if (errorDetails.size() > 20) {\n",
    "                System.out.println(\"    ...\");\n",
    "            }\n",
    "        }\n",
    "\n",
    "        // Make sure that the students solution is better than all baselines\n",
    "        for (Entry<String, double[]> baseResult : f1ForClassGuessers.entrySet()) {\n",
    "            if (baseResult.getValue()[2] >= solutionPerformance[2]) {\n",
    "                StringBuilder builder = new StringBuilder();\n",
    "                builder.append(\"Your solution is not better than a classifier that always chooses the \\\"\");\n",
    "                builder.append(baseResult.getKey());\n",
    "                builder.append(\"\\\" class.\");\n",
    "                Assertions.fail(builder.toString());\n",
    "            }\n",
    "        }\n",
    "        if ((minF1Score > 0) && (minF1Score > solutionPerformance[2])) {\n",
    "            Assertions.fail(\"Your solution did not reach the expected F1-score of \" + minF1Score);\n",
    "        }\n",
    "        System.out.println(\"Test successfully completed.\");\n",
    "    } catch (\n",
    "\n",
    "    AssertionFailedError e) {\n",
    "        throw e;\n",
    "    } catch (Throwable e) {\n",
    "        System.err.println(\"Your solution caused an unexpected error:\");\n",
    "        throw e;\n",
    "    }\n",
    "}\n",
    "/**\n",
    " * Simple method for calculating micro precision, recall and F1-measure.\n",
    " */\n",
    "public static double[] calcStats(int tp, int fp, int fn) {\n",
    "    double precision = tp / (double) (tp + fp);\n",
    "    double recall = tp / (double) (tp + fn);\n",
    "    return new double[] { precision, recall, (2 * precision * recall) / (precision + recall) };\n",
    "}\n",
    "\n",
    "System.out.println(\"---------- Simple example corpus ----------\");\n",
    "List<ClassifiedDocument> exampleCorpusTrain = Arrays.asList(\n",
    "        new ClassifiedDocument(new HashSet<String>(Arrays.asList(\"chess\")),\n",
    "                \"white king, black rook, black queen, white pawn, black knight, white bishop.\"),\n",
    "        new ClassifiedDocument(new HashSet<String>(Arrays.asList(\"history\")),\n",
    "                \"knight person granted honorary title knighthood\"),\n",
    "        new ClassifiedDocument(new HashSet<String>(Arrays.asList(\"history\")),\n",
    "                \"knight order eligibility, knighthood, head of state, king, prelate, middle ages.\"),\n",
    "        new ClassifiedDocument(new HashSet<String>(Arrays.asList(\"chess\", \"game\")),\n",
    "                \"Defense knight king pawn opening game opponent.\"),\n",
    "        new ClassifiedDocument(new HashSet<String>(Arrays.asList(\"game\")),\n",
    "                \"Game. player opponent victory. draw.\"));\n",
    "List<ClassifiedDocument> exampleCorpusTest = Arrays.asList(\n",
    "        new ClassifiedDocument(new HashSet<String>(Arrays.asList(\"history\")), \"Knighthood Middle Ages.\"),\n",
    "        new ClassifiedDocument(new HashSet<String>(Arrays.asList(\"game\", \"chess\")),\n",
    "                \"player black knight opponent pawn queen checkmate game draw victory.\"),\n",
    "        // document with unknown words\n",
    "        new ClassifiedDocument(new HashSet<String>(Arrays.asList(\"game\")), \"player opponent opening\"));\n",
    "checkClassifier(exampleCorpusTrain, exampleCorpusTest, 0);\n",
    "\n",
    "System.out.println();\n",
    "System.out.println(\"---------- Larger example corpus ----------\");\n",
    "List<ClassifiedDocument> classificationData = readClassData(\"/srv/distribution/multi-class-train.tsv\");\n",
    "checkClassifier(classificationData.subList(0, 600), classificationData.subList(600, classificationData.size()),\n",
    "        0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "fc4723f8815725c44713410c8d9ce586",
     "grade": true,
     "grade_id": "cell-autograde-1",
     "locked": true,
     "points": 4,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "// Ignore this cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "2280a65ff154fb7d12936e76235be051",
     "grade": true,
     "grade_id": "cell-autograde-2",
     "locked": true,
     "points": 3,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "// Ignore this cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "0ba1b93c7dc47996a5c81821c0c7c5cd",
     "grade": true,
     "grade_id": "cell-autograde-3",
     "locked": true,
     "points": 3,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "// Ignore this cell"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Java",
   "language": "java",
   "name": "java"
  },
  "language_info": {
   "codemirror_mode": "java",
   "file_extension": ".java",
   "mimetype": "text/x-java-source",
   "name": "Java",
   "pygments_lexer": "java",
   "version": "11.0.1+13-LTS"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
